{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "iVzQpslkicm-"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = [\"my name is kebing\", \"I don't like green onion\", \"I like ice cream\"]"
      ],
      "metadata": {
        "id": "tFIo9TdFik63"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# max_tokens: maximum size of the vocabulary for this layer\n",
        "tokenizer = tf.keras.layers.TextVectorization(max_tokens=10)\n",
        "# computes a vocabulary of string terms from tokens in a datset\n",
        "tokenizer.adapt(sentences)"
      ],
      "metadata": {
        "id": "_Mn1br_ni3BR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer(sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UgiUMHm6lHiu",
        "outputId": "2f4a2761-02dc-435e-8635-897eb30ab05d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 5), dtype=int64, numpy=\n",
              "array([[6, 5, 8, 7, 0],\n",
              "       [3, 1, 2, 1, 4],\n",
              "       [3, 2, 9, 1, 0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# OOV is [UNK]\n",
        "tokenizer(\"I like strawberries\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LUhS_kven3FW",
        "outputId": "a3ad03b6-dda4-4d95-a491-9f8984626a2c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3,), dtype=int64, numpy=array([3, 2, 1])>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.get_vocabulary(include_special_tokens=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "diC3Zl2knZEv",
        "outputId": "4eba19d7-c5e6-4d18-c914-645964bc22b3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['', '[UNK]', 'like', 'i', 'onion', 'name', 'my', 'kebing', 'is', 'ice']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pad the Sequences"
      ],
      "metadata": {
        "id": "CQfG3EYwbmoE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = tokenizer(sentences)\n",
        "# maxlen: maximum length of all sequences, default to longest\n",
        "padded = tf.keras.preprocessing.sequence.pad_sequences(sequences, maxlen=10)\n",
        "print(padded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7WqMfJSbh_u",
        "outputId": "4be2bc62-3fcd-49a1-dc16-c60247eb93e2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 0 0 0 0 6 5 8 7 0]\n",
            " [0 0 0 0 0 3 1 2 1 4]\n",
            " [0 0 0 0 0 3 2 9 1 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# truncating default to pre\n",
        "tf.keras.preprocessing.sequence.pad_sequences(sequences, maxlen=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCcqal9_cCFI",
        "outputId": "a257472f-2a2e-4df7-ece8-34b3872bc421"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[8, 7, 0],\n",
              "       [2, 1, 4],\n",
              "       [9, 1, 0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# truncate the post part\n",
        "tf.keras.preprocessing.sequence.pad_sequences(sequences, maxlen=3, truncating=\"post\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rF9voDyOcI6u",
        "outputId": "924d10f3-1804-45f5-e291-c162b69fbe06"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[6, 5, 8],\n",
              "       [3, 1, 2],\n",
              "       [3, 2, 9]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.preprocessing.sequence.pad_sequences(sequences, maxlen=15, padding=\"post\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Swo9JJcZc6f_",
        "outputId": "bb93358e-622b-441f-d7a9-dea880acbb13"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[6, 5, 8, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [3, 1, 2, 1, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [3, 2, 9, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences_oov = [\"it is not in vocabulary\", \"extremely involved content\"]\n",
        "oov_sequences = tokenizer(sentences_oov)\n",
        "print(oov_sequences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5c7xbBVddNKH",
        "outputId": "831f0669-6db5-4e42-b960-f64c4d12fb36"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[1 8 1 1 1]\n",
            " [1 1 1 0 0]], shape=(2, 5), dtype=int64)\n"
          ]
        }
      ]
    }
  ]
}