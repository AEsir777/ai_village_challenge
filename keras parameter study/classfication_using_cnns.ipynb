{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bdd9a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3d16af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfa5c6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the data set \n",
    "ds, metadata = tfds.load('fashion_mnist', as_supervised=True, with_info=True)\n",
    "train_ds, test_ds = ds['train'], ds['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b69f8f8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tfds.core.DatasetInfo(\n",
       "    name='fashion_mnist',\n",
       "    full_name='fashion_mnist/3.0.1',\n",
       "    description=\"\"\"\n",
       "    Fashion-MNIST is a dataset of Zalando's article images consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 grayscale image, associated with a label from 10 classes.\n",
       "    \"\"\",\n",
       "    homepage='https://github.com/zalandoresearch/fashion-mnist',\n",
       "    data_path='C:\\\\Users\\\\AEsir\\\\tensorflow_datasets\\\\fashion_mnist\\\\3.0.1',\n",
       "    file_format=tfrecord,\n",
       "    download_size=29.45 MiB,\n",
       "    dataset_size=36.42 MiB,\n",
       "    features=FeaturesDict({\n",
       "        'image': Image(shape=(28, 28, 1), dtype=tf.uint8),\n",
       "        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),\n",
       "    }),\n",
       "    supervised_keys=('image', 'label'),\n",
       "    disable_shuffling=False,\n",
       "    splits={\n",
       "        'test': <SplitInfo num_examples=10000, num_shards=1>,\n",
       "        'train': <SplitInfo num_examples=60000, num_shards=1>,\n",
       "    },\n",
       "    citation=\"\"\"@article{DBLP:journals/corr/abs-1708-07747,\n",
       "      author    = {Han Xiao and\n",
       "                   Kashif Rasul and\n",
       "                   Roland Vollgraf},\n",
       "      title     = {Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning\n",
       "                   Algorithms},\n",
       "      journal   = {CoRR},\n",
       "      volume    = {abs/1708.07747},\n",
       "      year      = {2017},\n",
       "      url       = {http://arxiv.org/abs/1708.07747},\n",
       "      archivePrefix = {arXiv},\n",
       "      eprint    = {1708.07747},\n",
       "      timestamp = {Mon, 13 Aug 2018 16:47:27 +0200},\n",
       "      biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1708-07747},\n",
       "      bibsource = {dblp computer science bibliography, https://dblp.org}\n",
       "    }\"\"\",\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a67720b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T-shirt/top',\n",
       " 'Trouser',\n",
       " 'Pullover',\n",
       " 'Dress',\n",
       " 'Coat',\n",
       " 'Sandal',\n",
       " 'Shirt',\n",
       " 'Sneaker',\n",
       " 'Bag',\n",
       " 'Ankle boot']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels=metadata.features['label']\n",
    "labels.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92cf7b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = metadata.splits['train'].num_examples\n",
    "test_size = metadata.splits['test'].num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "417296db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(images, labels):\n",
    "    images = tf.cast(images, tf.float32)\n",
    "    images /= 255\n",
    "    return images, labels\n",
    "\n",
    "train_ds = train_ds.map(normalize).cache()\n",
    "test_ds = test_ds.map(normalize).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d70339c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), padding='same', activation=tf.nn.relu,\n",
    "                          input_shape=(28, 28, 1)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2), strides=2),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), padding='same', activation=tf.nn.relu,\n",
    "                          input_shape=(28, 28, 1)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2), strides=2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "453a7848",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3bb6d17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "train_ds_batch = train_ds.cache().repeat().shuffle(train_size).batch(BATCH_SIZE)\n",
    "test_ds_batch = test_ds.cache().cache().batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "53f07bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c3834cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 44s 23ms/step - loss: 0.4279 - accuracy: 0.8397\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 43s 23ms/step - loss: 0.2841 - accuracy: 0.8934\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 41s 22ms/step - loss: 0.2417 - accuracy: 0.9108\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 41s 22ms/step - loss: 0.2090 - accuracy: 0.9231\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 40s 21ms/step - loss: 0.1826 - accuracy: 0.9331\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1dc6c0a5280>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_ds_batch, epochs=5, steps_per_epoch=math.ceil(train_size/BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ca3580fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 6ms/step - loss: 0.2509 - accuracy: 0.9130\n",
      "test accuracy is 0.9129999876022339\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_ds_batch, steps = math.ceil(test_size/BATCH_SIZE))\n",
    "print('test accuracy is {}'.format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25dd6f83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ac3805a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 41s 22ms/step - loss: 0.1581 - accuracy: 0.9416\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1dc010f9640>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for training epoch as 1\n",
    "model.fit(train_ds_batch, epochs=1, steps_per_epoch=math.ceil(train_size/BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "08904da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 6ms/step - loss: 0.2623 - accuracy: 0.9086\n"
     ]
    }
   ],
   "source": [
    "test_losses, test_accuracy = model.evaluate(test_ds_batch, steps = math.ceil(test_size/BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cb2d3f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_neurons(neuron_num):\n",
    "    print('number of neurons in the dense layer: {}'.format(neuron_num))\n",
    "    model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), padding='same', activation=tf.nn.relu,\n",
    "                           input_shape=(28, 28, 1)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2), strides=2),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), padding='same', activation=tf.nn.relu,\n",
    "                           input_shape=(28, 28, 1)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2), strides=2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(neuron_num, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "     metrics=['accuracy'])\n",
    "    model.fit(train_ds_batch, epochs=5, steps_per_epoch=math.ceil(train_size / BATCH_SIZE))\n",
    "    test_losses, test_accuracy = model.evaluate(test_ds_batch, steps = math.ceil(test_size / BATCH_SIZE))\n",
    "    return test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b517f416",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of neurons in the dense layer: 10\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 29s 15ms/step - loss: 0.6174 - accuracy: 0.7821\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 28s 15ms/step - loss: 0.3508 - accuracy: 0.8759\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 29s 16ms/step - loss: 0.3017 - accuracy: 0.8931\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 29s 16ms/step - loss: 0.2685 - accuracy: 0.9049\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 35s 19ms/step - loss: 0.2414 - accuracy: 0.9137\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.2957 - accuracy: 0.8967\n",
      "number of neurons in the dense layer: 100\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 40s 21ms/step - loss: 0.4156 - accuracy: 0.8504\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 38s 20ms/step - loss: 0.2627 - accuracy: 0.9046\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 35s 19ms/step - loss: 0.2174 - accuracy: 0.9201\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 36s 19ms/step - loss: 0.1865 - accuracy: 0.9319\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 39s 21ms/step - loss: 0.1631 - accuracy: 0.9387\n",
      "313/313 [==============================] - 2s 6ms/step - loss: 0.2361 - accuracy: 0.9169\n",
      "number of neurons in the dense layer: 256\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 51s 26ms/step - loss: 0.3794 - accuracy: 0.8615\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 46s 24ms/step - loss: 0.2455 - accuracy: 0.9094\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 49s 26ms/step - loss: 0.1974 - accuracy: 0.9281\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 50s 27ms/step - loss: 0.1690 - accuracy: 0.9375\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 49s 26ms/step - loss: 0.1389 - accuracy: 0.9481\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.2413 - accuracy: 0.9183\n",
      "number of neurons in the dense layer: 512\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 70s 37ms/step - loss: 0.3756 - accuracy: 0.8647\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 67s 36ms/step - loss: 0.2351 - accuracy: 0.9143\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 71s 38ms/step - loss: 0.1939 - accuracy: 0.9279\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 74s 39ms/step - loss: 0.1547 - accuracy: 0.9427\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 75s 40ms/step - loss: 0.1283 - accuracy: 0.9525\n",
      "313/313 [==============================] - 2s 7ms/step - loss: 0.2534 - accuracy: 0.9176\n"
     ]
    }
   ],
   "source": [
    "neuron_array = [10, 100, 256, 512]\n",
    "accuracy = []\n",
    "for num in neuron_array:\n",
    "    accuracy.append(diff_neurons(num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "12cf872f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3a3be329",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num of neurons in first dense layer</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>0.8967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>0.9169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>256</td>\n",
       "      <td>0.9183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>512</td>\n",
       "      <td>0.9176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num of neurons in first dense layer  accuracy\n",
       "0                                   10    0.8967\n",
       "1                                  100    0.9169\n",
       "2                                  256    0.9183\n",
       "3                                  512    0.9176"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {'num of neurons in first dense layer': neuron_array, 'accuracy': accuracy}\n",
    "pd.DataFrame(data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "740663e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_neurons_add_layer(neuron_num):\n",
    "    print('number of neurons in the dense layer: {}'.format(neuron_num))\n",
    "    model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), padding='same', activation=tf.nn.relu,\n",
    "                           input_shape=(28, 28, 1)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2), strides=2),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), padding='same', activation=tf.nn.relu,\n",
    "                           input_shape=(28, 28, 1)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2), strides=2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(neuron_num, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "     metrics=['accuracy'])\n",
    "    model.fit(train_ds_batch, epochs=5, steps_per_epoch=math.ceil(train_size / BATCH_SIZE))\n",
    "    test_losses, test_accuracy = model.evaluate(test_ds_batch, steps = math.ceil(test_size / BATCH_SIZE))\n",
    "    return test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "68883945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of neurons in the dense layer: 10\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 39s 20ms/step - loss: 0.4700 - accuracy: 0.8322\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 37s 20ms/step - loss: 0.2863 - accuracy: 0.8951\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 40s 21ms/step - loss: 0.2383 - accuracy: 0.9133\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 42s 23ms/step - loss: 0.2070 - accuracy: 0.9242\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 42s 22ms/step - loss: 0.1773 - accuracy: 0.9337\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.2514 - accuracy: 0.9100\n",
      "number of neurons in the dense layer: 50\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 40s 21ms/step - loss: 0.4129 - accuracy: 0.8509\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 41s 22ms/step - loss: 0.2577 - accuracy: 0.9043\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 38s 20ms/step - loss: 0.2145 - accuracy: 0.9208\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 38s 20ms/step - loss: 0.1822 - accuracy: 0.9326\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 42s 22ms/step - loss: 0.1589 - accuracy: 0.9415\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.2605 - accuracy: 0.9149\n",
      "number of neurons in the dense layer: 128\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 41s 21ms/step - loss: 0.4052 - accuracy: 0.8532\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 39s 21ms/step - loss: 0.2549 - accuracy: 0.9059\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 39s 21ms/step - loss: 0.2117 - accuracy: 0.9226\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 38s 20ms/step - loss: 0.1757 - accuracy: 0.9349\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 38s 20ms/step - loss: 0.1566 - accuracy: 0.9420\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.2368 - accuracy: 0.9196\n",
      "number of neurons in the dense layer: 180\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 39s 20ms/step - loss: 0.4165 - accuracy: 0.8483\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 38s 20ms/step - loss: 0.2658 - accuracy: 0.9026\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 38s 20ms/step - loss: 0.2176 - accuracy: 0.9198\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 38s 20ms/step - loss: 0.1857 - accuracy: 0.9316\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 39s 21ms/step - loss: 0.1534 - accuracy: 0.9413\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.2523 - accuracy: 0.9148\n"
     ]
    }
   ],
   "source": [
    "neuron_array = [10, 50, 128, 180]\n",
    "accuracy = []\n",
    "for num in neuron_array:\n",
    "    accuracy.append(diff_neurons_add_layer(num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6b6d5903",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num of neurons in first dense layer</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>0.9100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>0.9149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>128</td>\n",
       "      <td>0.9196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>180</td>\n",
       "      <td>0.9148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num of neurons in first dense layer  accuracy\n",
       "0                                   10    0.9100\n",
       "1                                   50    0.9149\n",
       "2                                  128    0.9196\n",
       "3                                  180    0.9148"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {'num of neurons in first dense layer': neuron_array, 'accuracy': accuracy}\n",
    "pd.DataFrame(data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c2cfe6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1c228cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 39s 20ms/step - loss: 0.5207 - accuracy: 0.8576\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 39s 21ms/step - loss: 0.2712 - accuracy: 0.8998\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 38s 20ms/step - loss: 0.2318 - accuracy: 0.9142\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 38s 20ms/step - loss: 0.2078 - accuracy: 0.9225\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 38s 20ms/step - loss: 0.1888 - accuracy: 0.9302\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1dc6a318460>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# don't normalize the model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), padding='same', activation=tf.nn.relu,\n",
    "                          input_shape=(28, 28, 1)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2), strides=2),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), padding='same', activation=tf.nn.relu,\n",
    "                          input_shape=(28, 28, 1)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2), strides=2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "             metrics=['accuracy'])\n",
    "train_ds, test_ds = ds['train'], ds['test']\n",
    "BATCH_SIZE = 32\n",
    "train_ds_batch = train_ds.cache().repeat().shuffle(train_size).batch(BATCH_SIZE)\n",
    "test_ds_batch = test_ds.cache().cache().batch(BATCH_SIZE)\n",
    "model.fit(train_ds_batch, epochs=5, steps_per_epoch=math.ceil(train_size / BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "30292502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 5ms/step - loss: 0.2937 - accuracy: 0.9005\n"
     ]
    }
   ],
   "source": [
    "test_losses, test_accuracy = model.evaluate(test_ds_batch, steps=math.ceil(test_size/BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b632440d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scenario</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CNN(epochs=5)</td>\n",
       "      <td>0.9130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>epochs=1</td>\n",
       "      <td>0.9086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>don't normalize</td>\n",
       "      <td>0.9005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          scenario accuracy\n",
       "0    CNN(epochs=5)   0.9130\n",
       "1         epochs=1   0.9086\n",
       "2  don't normalize   0.9005"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {'scenario': ['CNN(epochs=5)', 'epochs=1', \"don't normalize\"],\n",
    "       'accuracy': ['0.9130', '0.9086', '0.9005']}\n",
    "pd.DataFrame(data=data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
